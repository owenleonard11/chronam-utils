{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "This notebook shows the process of using the Chronicling America API to search for a selection of newspapers and download the XML OCR data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # for retrieving web data\n",
    "from xml.etree import ElementTree as ET # for parsing XML\n",
    "from time import sleep # for waiting to avoid rate limitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Globals and Config\n",
    "This cell defines global variables and notebook-wide configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True # set this flag for detailed output from cells.\n",
    "\n",
    "DATA_DIR = './data/'   # path to data directory\n",
    "TXT_PATH = 'pages.txt' # path to text file to hold page IDs\n",
    "\n",
    "DATA_URL   = 'https://chroniclingamerica.loc.gov/' # path for file downloads\n",
    "SEARCH_URL = 'https://chroniclingamerica.loc.gov/search/pages/results/' # path for id search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Pages\n",
    "This cell uses the [Chronicling America API](https://chroniclingamerica.loc.gov/about/api/) to find relevant pages from the collection. The example below retrieves a JSON summary of the first 1000 results for New York newspapers containing the word \"California\" between 1900 and 1914 and stores the ID of each page in a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "received response for page 1, containing items 1-21\n",
      "received response for page 2, containing items 21-41\n",
      "received response for page 3, containing items 41-61\n",
      "received response for page 4, containing items 61-81\n",
      "received response for page 5, containing items 81-101\n",
      "received response for page 6, containing items 101-121\n",
      "received response for page 7, containing items 121-141\n",
      "received response for page 8, containing items 141-161\n",
      "received response for page 9, containing items 161-181\n",
      "received response for page 10, containing items 181-201\n",
      "received response for page 11, containing items 201-221\n",
      "received response for page 12, containing items 221-241\n",
      "received response for page 13, containing items 241-261\n",
      "received response for page 14, containing items 261-281\n",
      "received response for page 15, containing items 281-301\n",
      "received response for page 16, containing items 301-321\n",
      "received response for page 17, containing items 321-341\n",
      "received response for page 18, containing items 341-361\n",
      "received response for page 19, containing items 361-381\n",
      "received response for page 20, containing items 381-401\n",
      "received response for page 21, containing items 401-421\n",
      "received response for page 22, containing items 421-441\n",
      "received response for page 23, containing items 441-461\n",
      "received response for page 24, containing items 461-481\n",
      "received response for page 25, containing items 481-501\n",
      "received response for page 26, containing items 501-521\n",
      "received response for page 27, containing items 521-541\n",
      "received response for page 28, containing items 541-561\n",
      "received response for page 29, containing items 561-581\n",
      "received response for page 30, containing items 581-601\n",
      "received response for page 31, containing items 601-621\n",
      "received response for page 32, containing items 621-641\n",
      "received response for page 33, containing items 641-661\n",
      "received response for page 34, containing items 661-681\n",
      "received response for page 35, containing items 681-701\n",
      "received response for page 36, containing items 701-721\n",
      "received response for page 37, containing items 721-741\n",
      "received response for page 38, containing items 741-761\n",
      "received response for page 39, containing items 761-781\n",
      "received response for page 40, containing items 781-801\n",
      "received response for page 41, containing items 801-821\n",
      "received response for page 42, containing items 821-841\n",
      "received response for page 43, containing items 841-861\n",
      "received response for page 44, containing items 861-881\n",
      "received response for page 45, containing items 881-901\n",
      "received response for page 46, containing items 901-921\n",
      "received response for page 47, containing items 921-941\n",
      "received response for page 48, containing items 941-961\n",
      "received response for page 49, containing items 961-981\n",
      "received response for page 50, containing items 981-1001\n"
     ]
    }
   ],
   "source": [
    "options = {\n",
    "    \"state\": \"New York\",\n",
    "\n",
    "    \"dateFilterType\" : \"yearRange\",\n",
    "    \"date1\"          : \"1900\",\n",
    "    \"date2\"          : \"1914\",\n",
    "\n",
    "    \"ortext\"     : \"\",\n",
    "    \"andtext\"    : \"California\",\n",
    "    \"phrasetext\" : \"\"\n",
    "}\n",
    "n_pages = 50 # 1000 items at 20 items per response\n",
    "\n",
    "base_qstr = '&'.join(f'{key}={value.replace(\" \", \"+\")}' for key, value in options.items()) + '&format=json'\n",
    "\n",
    "with open(DATA_DIR + TXT_PATH, 'w') as fp:\n",
    "    for n in range(1, n_pages + 1):\n",
    "        response = requests.get(f'{SEARCH_URL}?{base_qstr}&page={n}').json()\n",
    "        if verbose:\n",
    "            print(f'received response for page {n}, containing items {response[\"startIndex\"]}-{response[\"startIndex\"] + 20}')\n",
    "        for item in response['items']:\n",
    "            fp.write(item['id'] + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting XML\n",
    "This cell retrieves OCR XML files from list of page IDs generated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XML_DIR = 'xml/'\n",
    "\n",
    "def download_xml(id: str) -> str | None:\n",
    "    try:\n",
    "        response = requests.get(f'{DATA_URL}{id}ocr.xml')\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        if verbose:\n",
    "            print(f'bad response for {DATA_URL}{id}ocr.xml')\n",
    "            return None\n",
    "\n",
    "    xml = ET.ElementTree(ET.fromstring(response.content))\n",
    "    ET.indent(xml, space=\"\\t\", level=0)\n",
    "\n",
    "    filename = id.replace('/', '')\n",
    "    with open(f'{DATA_DIR}{XML_DIR}{filename}.xml', 'w'): pass\n",
    "    xml.write(f'{DATA_DIR}{XML_DIR}{filename}.xml')\n",
    "\n",
    "    return filename\n",
    "\n",
    "id_list = []\n",
    "with open(f'{DATA_DIR}{TXT_PATH}') as fp:\n",
    "    while(id := fp.readline()):\n",
    "        id_list.append(id[:-1])\n",
    "        \n",
    "for id in id_list:\n",
    "    download_xml(id)\n",
    "    sleep(1) ## see https://libraryofcongress.github.io/data-exploration/loc.gov%20JSON%20API/Chronicling_America/README.html#rate-limits-and-definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad response for https://chroniclingamerica.loc.gov//lccn/sn83030272/1914-10-11/ed-1/seq-52/ocr.xml\n"
     ]
    }
   ],
   "source": [
    "download_xml('/lccn/sn83030272/1914-10-11/ed-1/seq-52/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
